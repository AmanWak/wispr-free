# Wispr Free

**A free, open-source, fully local speech-to-text tool for macOS.**

Hold a key, speak, release ‚Äî your words are transcribed and pasted instantly into any app. No cloud, no subscription, no API keys. Everything runs on your machine.

> Inspired by [Wispr Flow](https://wisprflow.ai/) ‚Äî this is a free alternative that works entirely offline.

---

## Demo

```
$ python3 wispr_free.py

üöÄ Wispr Free ‚Äî Hold-to-Dictate
==================================================
  Trigger key  : Right Option
  Whisper model: base
  Language     : en
  Auto-paste   : on
  Custom vocab : 3 words
  Command API  : purdue

  Hold trigger key ‚Üí speak ‚Üí release to transcribe & paste
  Say "scratch that" to delete the last transcription
  Press Ctrl+C to quit
==================================================

üìñ Custom vocabulary: Aman, FAANG, Wispr

‚úÖ Model loaded!
üëÇ Listening for Right Option key...

üé§ Recording...
‚öôÔ∏è  Transcribing...
‚úÖ "Hey this is a test of the speech to text tool"
üìã Pasted!

üé§ Recording...
‚öôÔ∏è  Transcribing...
‚úÖ "Scratch that."
üîç Command detected (local): delete last
üóëÔ∏è  Deleted: "Hey this is a test of the speech to text tool"
```

---

## How It Works

1. **You hold down Right Option (‚å•)** ‚Äî the mic starts streaming audio
2. **You speak** ‚Äî audio frames are captured in real time
3. **You release the key** ‚Äî recording stops, audio is sent to Whisper
4. **Whisper transcribes** your speech locally (no internet needed)
5. **Text is auto-pasted** into whatever app/text field you're using (Notes, Chrome, Slack, anywhere)

If no text field is focused, the text stays on your clipboard ‚Äî just ‚åòV wherever you want.

### Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Key Listener Thread ‚îÇ  ‚Üê pynput detects Right Option press/release
‚îÇ  (pynput)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ on_press ‚Üí start mic
       ‚îÇ on_release ‚Üí stop mic, enqueue audio
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Worker Thread       ‚îÇ  ‚Üê dequeues audio, runs Whisper, handles result
‚îÇ  (threading)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚Üí Whisper transcribe (local, with custom vocab prompt)
       ‚îú‚îÄ‚Üí CommandDetector: is it "scratch that"?
       ‚îÇ     ‚îú‚îÄ YES (local regex or LLM API) ‚Üí ‚åòZ undo last paste
       ‚îÇ     ‚îî‚îÄ NO ‚Üí continue to paste
       ‚îú‚îÄ‚Üí pbcopy (clipboard)
       ‚îî‚îÄ‚Üí simulated ‚åòV (pynput Controller)
```

All three threads (main, listener, worker) run concurrently so the key listener never blocks during transcription.

---

## Installation

### Prerequisites

- **macOS** (uses `pbcopy` for clipboard and `pynput` for global hotkeys)
- **Python 3.10+**
- **ffmpeg** (required by Whisper for audio decoding)

### Steps

```bash
# 1. Install ffmpeg (if you don't have it)
brew install ffmpeg

# 2. Install Python dependencies
pip3 install openai-whisper sounddevice soundfile numpy pynput

# 3. Fix SSL certificates (if you get SSL errors on first run)
#    Run the certificate installer that ships with your Python version:
/Applications/Python\ 3.13/Install\ Certificates.command

# 4. Clone this repo (or just download wispr_free.py)
git clone https://github.com/YOUR_USERNAME/wispr-free.git
cd wispr-free
```

### macOS Permissions

On first run, macOS will ask for permissions. Grant these in **System Settings ‚Üí Privacy & Security**:

| Permission | What to add | Why |
|---|---|---|
| **Input Monitoring** | Your terminal app (Terminal.app, iTerm2, etc.) | So pynput can detect global key presses |
| **Accessibility** | Your terminal app | So pynput can simulate ‚åòV to paste |
| **Microphone** | Prompted automatically | So sounddevice can record audio |

> **After granting permissions, restart your terminal** for them to take effect.

---

## Usage

### Basic (defaults)

```bash
python3 wispr_free.py
```

This uses the `tiny` model, Right Option (‚å•) trigger key, English language, and auto-paste enabled.

### Command-Line Options

```
python3 wispr_free.py [OPTIONS]
python3 wispr_free.py vocab {add|remove|list|clear} [WORDS...]

Dictation Options:
  -m, --model {tiny,base,small,medium,large}
        Whisper model size (default: base)

  -t, --trigger {right_option,left_option,right_cmd,left_ctrl,right_ctrl,caps_lock,f13..f20}
        Key to hold while speaking (default: right_option)

  -l, --language LANG
        ISO 639-1 language code (default: en)

  --no-paste
        Disable auto-paste, only copy to clipboard

  --api-provider {gemini,purdue,none}
        LLM API for smart command detection (default: none)

  --api-key KEY
        API key (or use WISPR_GEMINI_API_KEY / WISPR_PURDUE_API_KEY env vars)

  --api-model MODEL
        Override default LLM model for command detection

  -h, --help
        Show help message

Vocabulary Commands:
  vocab add <words...>     Add custom words for better recognition
  vocab remove <words...>  Remove custom words
  vocab list               Show all custom words
  vocab clear              Remove all custom words
```

### Examples

```bash
# Use the base model for better accuracy
python3 wispr_free.py --model base

# Use Right Command as trigger key
python3 wispr_free.py --trigger right_cmd

# Transcribe Spanish
python3 wispr_free.py --language es

# Japanese, medium model, clipboard only
python3 wispr_free.py -m medium -l ja --no-paste

# Enable smart command detection with Purdue GenAI Studio
export WISPR_PURDUE_API_KEY="your-key-here"
python3 wispr_free.py --api-provider purdue

# Or with Google Gemini
export WISPR_GEMINI_API_KEY="your-key-here"
python3 wispr_free.py --api-provider gemini

# Set up a shell alias for quick access
echo 'alias wispr="python3 /path/to/wispr_free.py"' >> ~/.zshrc
source ~/.zshrc
wispr  # now just type this!
```

---

## Voice Commands ("Scratch That")

Wispr Free detects voice commands like **"scratch that"** and deletes the last transcription instead of pasting it.

### How it works

1. You dictate ‚Üí text is pasted
2. You say "scratch that" ‚Üí the last paste is **undone** (via ‚åòZ)

### Two detection modes

**Local (always on, no API):** Exact phrase matching for common commands:
- "scratch that", "delete that", "undo that", "undo"
- "never mind", "remove that", "erase that", "take that back"
- "go back", "backspace", "clear that", "oops"

**API-powered (optional):** For ambiguous cases, an LLM classifies whether the text is a command or normal dictation. This catches natural variations like "oh wait, scratch that actually" that exact matching would miss.

Supported APIs:

| Provider | Endpoint | Model | Env Variable |
|---|---|---|---|
| **Purdue GenAI Studio** | `genai.rcac.purdue.edu` | `llama3.1:latest` | `WISPR_PURDUE_API_KEY` |
| **Google Gemini** | `generativelanguage.googleapis.com` | `gemini-2.0-flash` | `WISPR_GEMINI_API_KEY` |

```bash
# Use Purdue GenAI Studio
export WISPR_PURDUE_API_KEY="your-purdue-api-key"
python3 wispr_free.py --api-provider purdue

# Use Google Gemini
export WISPR_GEMINI_API_KEY="your-gemini-api-key"
python3 wispr_free.py --api-provider gemini

# Or pass the key directly
python3 wispr_free.py --api-provider purdue --api-key "your-key"

# Use a different model
python3 wispr_free.py --api-provider purdue --api-model "llama3.3:latest"
```

> **Without an API key**, only exact local phrase matching is used. This is fast and works great for straightforward commands.

---

## Custom Vocabulary

Wispr Free lets you add custom words ‚Äî names, acronyms, technical terms ‚Äî that Whisper might otherwise mis-transcribe. These words are stored in `~/.wispr_free/custom_words.json` and persist across sessions.

### How it works

Custom words are injected into Whisper's `initial_prompt` parameter, which biases the decoder toward recognizing those tokens. This is especially useful for:

- **Names:** "Aman", "Wakankar", "Satya"
- **Acronyms:** "FAANG", "RCAC", "GenAI"
- **Brand names:** "Wispr", "Purdue", "macOS"
- **Technical terms:** "Kubernetes", "PostgreSQL", "NumPy"

### Managing vocabulary from the terminal

```bash
# Add words
python3 wispr_free.py vocab add "Aman" "FAANG" "Kubernetes"
# ‚úÖ Added: Aman, FAANG, Kubernetes
# üìñ Current vocabulary (3): Aman, FAANG, Kubernetes

# List all words
python3 wispr_free.py vocab list
# üìñ Custom vocabulary (3 words):
#    ‚Ä¢ Aman
#    ‚Ä¢ FAANG
#    ‚Ä¢ Kubernetes

# Remove specific words
python3 wispr_free.py vocab remove "FAANG"
# ‚úÖ Removed: FAANG

# Clear everything
python3 wispr_free.py vocab clear
# üóëÔ∏è  Cleared 2 word(s).
```

Words take effect immediately on the next dictation ‚Äî no restart needed.

---

## Whisper Models ‚Äî Which One Should I Use?

All models run fully offline after the first download.

| Model | Parameters | Download | RAM Usage | Speed (M1 Air) | Accuracy | Best For |
|---|---|---|---|---|---|---|
| **tiny** | 39M | ~75 MB | ~1 GB | ~1‚Äì2 sec | Good | Quick notes, casual dictation |
| **base** | 74M | ~142 MB | ~1 GB | ~2‚Äì3 sec | Better | Daily use, recommended starting point |
| **small** | 244M | ~466 MB | ~2 GB | ~4‚Äì6 sec | Great | Meetings, detailed transcription |
| **medium** | 769M | ~1.5 GB | ~5 GB | ~10‚Äì15 sec | Excellent | Professional, multi-language |
| **large** | 1550M | ~2.9 GB | ~10 GB | ~20‚Äì30 sec | Best | Maximum accuracy, complex audio |

> **Recommendation:** Start with `tiny` or `base`. Switch to `small` if you need better accuracy. Only use `medium`/`large` if accuracy is critical and you don't mind waiting.

### Switching Models

```bash
# Try base model
python3 wispr_free.py --model base

# Or edit the DEFAULT_MODEL variable in wispr_free.py:
DEFAULT_MODEL = "base"  # Change this line
```

The model is downloaded automatically on first use and cached at `~/.cache/whisper/`.

---

## Performance on Apple Silicon (M1 MacBook Air)

Wispr Free runs **great** on M1/M2/M3 Macs. Here's what to expect:

### Resource Usage (tiny model ‚Äî default)

| Resource | Idle (listening) | Recording | Transcribing |
|---|---|---|---|
| **CPU** | ~0% | ~1‚Äì2% | ~80‚Äì100% (brief burst) |
| **RAM** | ~150 MB (Python + model) | ~160 MB | ~180 MB peak |
| **Total with model** | ~1 GB | ~1 GB | ~1 GB |
| **Battery impact** | Negligible | Negligible | Minimal (1‚Äì2 sec bursts) |

### Resource Usage (base model)

| Resource | Idle | Recording | Transcribing |
|---|---|---|---|
| **CPU** | ~0% | ~1‚Äì2% | ~100% (2‚Äì3 sec) |
| **RAM** | ~200 MB | ~210 MB | ~250 MB peak |
| **Total with model** | ~1 GB | ~1 GB | ~1.1 GB |

### Resource Usage (small model)

| Resource | Idle | Recording | Transcribing |
|---|---|---|---|
| **CPU** | ~0% | ~1‚Äì2% | ~100% (4‚Äì6 sec) |
| **RAM** | ~500 MB | ~510 MB | ~600 MB peak |
| **Total with model** | ~2 GB | ~2 GB | ~2.2 GB |

### Key Performance Notes

- **M1/M2/M3 Macs** benefit hugely from Apple's Neural Engine ‚Äî Whisper runs faster than on equivalent x86 CPUs
- The `tiny` model transcribes ~30 seconds of audio in **1‚Äì2 seconds** on M1
- **Battery impact is minimal** ‚Äî the model only activates in short bursts when you release the trigger key. Between dictations, CPU usage is essentially zero
- 8 GB RAM Macs can comfortably run `tiny`, `base`, or `small` models alongside normal apps
- 16 GB RAM Macs can run `medium` without issues
- `large` model needs ~10 GB and is only recommended for 16+ GB machines with nothing else heavy running

---

## Code Structure

The codebase is organized into clean, modular classes so you can easily extend or modify it:

```
wispr_free.py
‚îÇ
‚îú‚îÄ‚îÄ Configuration         ‚Üê Model, sample rate, trigger keys, language, API settings
‚îÇ
‚îú‚îÄ‚îÄ class CustomVocabulary ‚Üê Persistent custom words (~/.wispr_free/custom_words.json)
‚îÇ   ‚îú‚îÄ‚îÄ add/remove/clear()‚Üê Manage word list
‚îÇ   ‚îî‚îÄ‚îÄ get_prompt()      ‚Üê Builds Whisper initial_prompt for vocab bias
‚îÇ
‚îú‚îÄ‚îÄ class CommandDetector  ‚Üê Detects "scratch that" / "delete that" commands
‚îÇ   ‚îú‚îÄ‚îÄ _local_detect()   ‚Üê Fast regex matching (always on)
‚îÇ   ‚îú‚îÄ‚îÄ _call_gemini()    ‚Üê Google Gemini API classification
‚îÇ   ‚îú‚îÄ‚îÄ _call_purdue()    ‚Üê Purdue GenAI Studio API classification
‚îÇ   ‚îî‚îÄ‚îÄ detect()          ‚Üê Returns {"action": "delete"} or None
‚îÇ
‚îú‚îÄ‚îÄ class Recorder        ‚Üê Microphone streaming (sounddevice)
‚îÇ   ‚îú‚îÄ‚îÄ start()           ‚Üê Opens mic InputStream with callback
‚îÇ   ‚îî‚îÄ‚îÄ stop() ‚Üí audio    ‚Üê Closes stream, returns numpy array
‚îÇ
‚îú‚îÄ‚îÄ class Transcriber     ‚Üê Speech-to-text (Whisper)
‚îÇ   ‚îú‚îÄ‚îÄ load()            ‚Üê Downloads & loads model into RAM
‚îÇ   ‚îî‚îÄ‚îÄ transcribe(audio, initial_prompt) ‚Üê Returns text string
‚îÇ
‚îú‚îÄ‚îÄ class OutputHandler   ‚Üê Clipboard + paste + undo (pbcopy + pynput)
‚îÇ   ‚îú‚îÄ‚îÄ deliver(text)     ‚Üê Copies to clipboard, simulates ‚åòV
‚îÇ   ‚îî‚îÄ‚îÄ delete_last()     ‚Üê Undoes last paste via ‚åòZ
‚îÇ
‚îú‚îÄ‚îÄ class WisprFree       ‚Üê Main app (wires everything together)
‚îÇ   ‚îú‚îÄ‚îÄ _on_press()       ‚Üê Trigger key pressed ‚Üí start recording
‚îÇ   ‚îú‚îÄ‚îÄ _on_release()     ‚Üê Trigger key released ‚Üí stop ‚Üí enqueue
‚îÇ   ‚îú‚îÄ‚îÄ _worker()         ‚Üê Background: transcribe ‚Üí detect command ‚Üí paste/delete
‚îÇ   ‚îî‚îÄ‚îÄ run()             ‚Üê Entry point: loads model, starts threads
‚îÇ
‚îú‚îÄ‚îÄ parse_args()          ‚Üê CLI parsing (dictation flags + vocab subcommand)
‚îî‚îÄ‚îÄ handle_vocab()        ‚Üê Vocab CLI handler (add/remove/list/clear)
```

### Extending It

**Want to add post-processing (grammar fix, summarization)?**
```python
# Add a method to WisprFree or create a new Processor class:
class Processor:
    def process(self, raw_text: str) -> str:
        # Your logic here (local LLM, API call, regex, etc.)
        return cleaned_text

# Then in _worker(), after transcription:
text = self.processor.process(text)
```

**Want to add a GUI notification?**
```python
# Use osascript to show a macOS notification:
import subprocess
subprocess.run([
    "osascript", "-e",
    f'display notification "{text}" with title "Wispr Free"'
])
```

**Want to support Linux?**
- Replace `pbcopy` with `xclip` or `xdotool` in `OutputHandler`
- Replace `pynput` keyboard simulation with `xdotool type`

**Want to log transcriptions?**
```python
# Add to OutputHandler.deliver():
with open("transcriptions.log", "a") as f:
    f.write(f"{time.strftime('%Y-%m-%d %H:%M:%S')} | {text}\n")
```

---

## Supported Languages

Whisper supports 99 languages. Pass any [ISO 639-1 code](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes):

```bash
python3 wispr_free.py --language es   # Spanish
python3 wispr_free.py --language fr   # French
python3 wispr_free.py --language de   # German
python3 wispr_free.py --language ja   # Japanese
python3 wispr_free.py --language zh   # Chinese
python3 wispr_free.py --language ko   # Korean
python3 wispr_free.py --language hi   # Hindi
python3 wispr_free.py --language ar   # Arabic
python3 wispr_free.py --language pt   # Portuguese
python3 wispr_free.py --language ru   # Russian
```

> For non-English languages, `small` or `medium` models give significantly better results than `tiny`.

---

## Trigger Key Options

| Key Name | Flag | Physical Key | Notes |
|---|---|---|---|
| `right_option` | `--trigger right_option` | Right ‚å• | **Default.** Rarely used standalone |
| `left_option` | `--trigger left_option` | Left ‚å• | May conflict with special characters |
| `right_cmd` | `--trigger right_cmd` | Right ‚åò | Good if you only use left ‚åò |
| `left_ctrl` | `--trigger left_ctrl` | Left ‚åÉ | Easy reach, may conflict in terminal |
| `right_ctrl` | `--trigger right_ctrl` | Right ‚åÉ | Rarely used |
| `caps_lock` | `--trigger caps_lock` | Caps Lock | Toggles caps ‚Äî use with caution |
| `f13`‚Äì`f20` | `--trigger f18` | F13‚ÄìF20 | Requires key remapping (Karabiner) |

> **Why not the `fn` key?** The `fn` key is handled at the hardware level by Apple's keyboard controller. macOS never receives it as a discrete key event, so no software can detect it.

---

## Troubleshooting

### "No audio captured" or silence

- Check **System Settings ‚Üí Privacy & Security ‚Üí Microphone** ‚Äî your terminal must be allowed
- Run `python3 -c "import sounddevice; print(sounddevice.query_devices())"` to verify your mic is detected
- Make sure your mic isn't muted or used by another app

### Key press not detected

- Grant **Input Monitoring** permission to your terminal app
- **Restart your terminal** after granting permissions
- Try a different trigger key: `python3 wispr_free.py --trigger right_cmd`

### Auto-paste not working

- Grant **Accessibility** permission to your terminal app
- **Restart your terminal** after granting
- Use `--no-paste` as a workaround (text will be on your clipboard)

### SSL error on first model download

```bash
# Run the Python certificate installer:
/Applications/Python\ 3.13/Install\ Certificates.command
# Adjust "3.13" to match your Python version
```

### Slow transcription

- Use a smaller model: `--model tiny`
- Close RAM-heavy apps if using `medium` or `large`
- Check Activity Monitor ‚Äî if Python is swapping to disk, you need a smaller model

---

## Dependencies

| Package | Version | Purpose |
|---|---|---|
| [openai-whisper](https://github.com/openai/whisper) | Latest | Local speech-to-text AI model |
| [sounddevice](https://python-sounddevice.readthedocs.io/) | Latest | Real-time microphone streaming |
| [soundfile](https://pysoundfile.readthedocs.io/) | Latest | WAV file writing for Whisper |
| [numpy](https://numpy.org/) | Latest | Audio buffer management |
| [pynput](https://pynput.readthedocs.io/) | Latest | Global hotkey detection + key simulation |
| [ffmpeg](https://ffmpeg.org/) | Latest | Audio decoding (system dependency) |

---

## License

MIT ‚Äî do whatever you want with it. Free as in beer, free as in speech.

---

## Contributing

PRs welcome! Some ideas:

- [x] Voice commands (‚Äúscratch that‚Äù) to delete last transcription
- [x] Custom vocabulary for names, acronyms, and technical terms
- [x] LLM-powered command detection (Gemini + Purdue GenAI Studio)
- [ ] Linux support (`xclip` / `xdotool` backend)
- [ ] Windows support (`pyperclip` / `pyautogui` backend)
- [ ] System tray icon with status indicator
- [ ] GUI settings panel
- [ ] macOS notification on transcription complete
- [ ] Transcription history / log file
- [ ] Custom Whisper model fine-tuning support
- [ ] Auto-punctuation post-processor
- [ ] Noise gate / silence trimming before transcription
